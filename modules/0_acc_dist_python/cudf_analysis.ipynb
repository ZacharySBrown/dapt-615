{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data_Analysis_With_Python_Complete.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZacharySBrown/dapt-615/blob/master/modules/0_acc_dist_python/cudf_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK9efjc7y4YX"
      },
      "source": [
        "# Install `RAPIDS` and Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNujrKYTzpMV"
      },
      "source": [
        "# Install RAPIDS\n",
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "!bash rapidsai-csp-utils/colab/rapids-colab.sh stable\n",
        "\n",
        "import sys, os\n",
        "\n",
        "dist_package_index = sys.path.index('/usr/local/lib/python3.6/dist-packages')\n",
        "sys.path = sys.path[:dist_package_index] + ['/usr/local/lib/python3.6/site-packages'] + sys.path[dist_package_index:]\n",
        "sys.path\n",
        "exec(open('rapidsai-csp-utils/colab/update_modules.py').read(), globals())\n",
        "\n",
        "!wget https://vcu-dapt-615.s3.amazonaws.com/covid_19_data.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5j0BtSPy4Yi"
      },
      "source": [
        "import cudf\n",
        "data = pd.read_csv('covid_19_data.csv')\n",
        "data.head()\n",
        "data = data.set_index(('Sno','ObservationDate'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBvrcSiXy4Yj"
      },
      "source": [
        "\n",
        "data.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcmYnW4py4Yj"
      },
      "source": [
        "data.loc[[(1,'01/22/2020')],:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UP-wL-0DfifT"
      },
      "source": [
        "# Understanding and Applying Data Analysis with Python\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaDUNi9efifV"
      },
      "source": [
        "## Outline\n",
        "\n",
        "1. File I/O and working with data in pandas\n",
        "\n",
        "    * Reading, writing, and creating structured data in Python\n",
        "    * Viewing, inspecting, and selecting data\n",
        "    \n",
        "    \n",
        "2. Exploratory data analysis with pandas\n",
        "\n",
        "    * Data cleaning\n",
        "    * Summary statistics\n",
        "    * Data transformations\n",
        "    * Sorting, aggregation, joins and pivots\n",
        "    * Data visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwHjPNURfifW"
      },
      "source": [
        "## Project Jupyter\n",
        "\n",
        "Project Jupyter exists to develop open-source software, open-standards, and services for interactive computing across dozens of programming languages. Jupyter supports over 40 programming languages, including Python, R, Julia, and Scala.\n",
        "\n",
        "The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning, and much more.\n",
        "\n",
        "Try Jupyter without installing anything: https://jupyter.org/try"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnapocRdfifW"
      },
      "source": [
        "## Novel Corona Virus 2019 Dataset: day level information on COVID-19 affected cases\n",
        "\n",
        "### About this dataset:\n",
        "\n",
        "https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset/data?select=covid_19_data.csv\n",
        "\n",
        "(original: Johns Hopkins Github repository: https://github.com/CSSEGISandData/COVID-19)\n",
        "\n",
        "Name of the file: \"covid_19_data.csv\"\n",
        "\n",
        "Columns description:\n",
        "\n",
        "- **Sno** - Serial number\n",
        "- **ObservationDate** - Date of the observation in MM/DD/YYYY\n",
        "- **Province/State** - Province or state of the observation (Could be empty when missing)\n",
        "- **Country/Region** - Country of observation\n",
        "- **Last Update** - Time in UTC at which the row is updated for the given province or country. (Not standardised and so please clean before using it)\n",
        "- **Confirmed** - Cumulative number of confirmed cases till that date\n",
        "- **Deaths** - Cumulative number of of deaths till that date\n",
        "- **Recovered** - Cumulative number of recovered cases till that date"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KAj_DrnfifX"
      },
      "source": [
        "## 1. File I/O and working with data in pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6yr6G7lfifa"
      },
      "source": [
        "### Reading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxzXP5USfifb"
      },
      "source": [
        "#To start working with cuDF, we need to import this library:\n",
        "import cudf\n",
        "\n",
        "#We'll also import the Pandas library as well for occassional performance comparisons:\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "DroxC_VOfifb"
      },
      "source": [
        "Most of the time, you will be probably working with data that already exists in variety of different formats.\n",
        "By far the most basic of these are CSV or Excel files. This is how you read these files with pandas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm3bqhg8fifb"
      },
      "source": [
        "#read CSV file in pandas:\n",
        "pd_covid = pd.read_csv('covid_19_data.csv')\n",
        "\n",
        "covid = cudf.from_pandas(pd_covid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJPjeymIfifb"
      },
      "source": [
        "Let's pause here for a minute, and try to understand what exactly happens once we run **pandas.read_csv** command.\n",
        "\n",
        "Two core objects in pandas are the **DataFrame** and the **Series**.\n",
        "\n",
        "A **DataFrame** is a table. It contains an array of individual entries, each of which has a certain value. Each entry corresponds to a row and a column. The list of row labels used in a DataFrame is known as an Index.\n",
        "\n",
        "In our example above, *covid* is a DataFrame created from 'covid_19_data.csv' file. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-50Lp5Xfifc"
      },
      "source": [
        "#We can examine the contents of our DataFrame using the head() command:\n",
        "covid.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2FrhcgSfifc"
      },
      "source": [
        "From this example, we can see that DataFrame entries are not limited to integers. For instance, there is an entry with value of \"Beijing\", which is a string."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOkm2TzYfifc"
      },
      "source": [
        "A **Series**, the second core pandas object, is a sequence of data values. If a DataFrame is a table, a Series is a list and,  in essence, it is a single column of a DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLMJ5EJxfifd"
      },
      "source": [
        "#This is how we can see all the Series names in our DataFrame:\n",
        "covid.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuZnlaayfifm"
      },
      "source": [
        "## Viewing, inspecting, and selecting data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcKn6QZgfifm"
      },
      "source": [
        "Let's return to our **covid** DataFrame. Remember - you can use *head()* method to view the first *n* rows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYmIpSHDfifm"
      },
      "source": [
        "#View first 3 rows of data set:\n",
        "covid.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMlFtrt6fifm"
      },
      "source": [
        "#In a similar way, you can inspect last n rows with tail() method:\n",
        "covid.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJeJ1g1qfifn"
      },
      "source": [
        "Pandas objects have a number of attributes enabling you to access the metadata. We can also use the **shape** attribute to check how large this DataFrame is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGPwqsAefifn"
      },
      "source": [
        "#Check the data set size:\n",
        "covid.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Pctr_Olfifo"
      },
      "source": [
        "To see list of all columns, use *columns* attribute:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2t3s2Pffifo"
      },
      "source": [
        "#See the list of all DataFrame columns:\n",
        "covid.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHLqxnrofifo"
      },
      "source": [
        "There are two ways to access values in any column within the DataFrame. One is the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWtsl6UKfifp"
      },
      "source": [
        "#Look at first 5 rows of 'ObservationDate' column:\n",
        "covid.ObservationDate.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VQ7XeEqfifp"
      },
      "source": [
        "And another way is to use Python indexing (**[ ]**) operator:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-SiIGbYfifp"
      },
      "source": [
        "#Look at first 5 rows of 'Last Update' column:\n",
        "covid['Last Update'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rePrgV3fifp"
      },
      "source": [
        "(The advantage of this way is that it handles column names with reserved characters in them.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvFPFkp-fifq"
      },
      "source": [
        "We can also select multiple columns by providing list of their names (this will return columns as a new DataFrame):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og6X_n8jfifq"
      },
      "source": [
        "#select multiple columns:\n",
        "covid[['ObservationDate', 'Confirmed', 'Recovered']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llrMDRTrfifq"
      },
      "source": [
        "To look at a single specific value within Series, we need to use the indexing operator once more:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sehpCW8Tfifq"
      },
      "source": [
        "covid['Province/State'][3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD7B29uLfifq"
      },
      "source": [
        "covid.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ8YXyOCfifr"
      },
      "source": [
        "In addition to Python-native indexing operator, we can also use **iloc** and **loc**. \n",
        "\n",
        "We use **iloc** to select data based on its numerical position. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrbW7QnOfifr"
      },
      "source": [
        "#Select first row of data:\n",
        "covid.iloc[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4HKtLvyfifr"
      },
      "source": [
        "#If, instead, we want to get first column of data, we would use:\n",
        "covid.iloc[:, 2].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwnzvKzwfifr"
      },
      "source": [
        "We use **loc** for label-based selection:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPoOwEBxfifr"
      },
      "source": [
        "covid.loc[:, ['ObservationDate', 'Country/Region', 'Confirmed']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IxdcUDSfifs"
      },
      "source": [
        "Usually, data selection based on *conditions* provides the most interesting insights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kyw9Npc-fifs"
      },
      "source": [
        "Let's take a look at Italy-related data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmYWeB5mfifs"
      },
      "source": [
        "#Select 'Italy' Country/Region data:\n",
        "covid[covid['Country/Region'] == 'Italy']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwAMXUCofifs"
      },
      "source": [
        "To see the number of confirmed cases in Italy as of April 13, we can use the apmersand (**&**) to bring the two questions together:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZbkXMMHfifs"
      },
      "source": [
        "#Confirmed cases in Italy as of April 13, 2020:\n",
        "covid[(covid['Country/Region'] == 'Italy') & (covid['ObservationDate'] == '04/13/2020')].Confirmed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tgA9WD0fift"
      },
      "source": [
        "If, instead, we are interested in seeing all the data related to California or Washington states in US, we would use a pipe (**|**):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rZm2VxWfift"
      },
      "source": [
        "covid[(covid['Country/Region'] == 'US') &\n",
        "      ((covid['Province/State'] == 'Washington') | (covid['Province/State'] == 'California'))].head(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7LcFQ8vfift"
      },
      "source": [
        "To get the same results, we might also use pandas built-in conditional selector **isin()**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lquLNtiSfift"
      },
      "source": [
        "#Alternative way of looking at all data relates to CA and WA states in US:\n",
        "covid[(covid['Country/Region'] == 'US') &\n",
        "      (covid['Province/State'].isin(['Washington', 'California']))].head(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QkakViefift"
      },
      "source": [
        "### Assigning data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga-utYPTfift"
      },
      "source": [
        "Sometimes we might want to re-write all the values within the Series. For example, we can create a new column \"Source\", and fill it in with \"Trusted\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPJwmGUHfifu"
      },
      "source": [
        "#Create a new \"Source\" column:\n",
        "covid['Source'] = 'Trusted'\n",
        "covid.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opcxDeEOfifu"
      },
      "source": [
        "## 2. Exploratory data analysis with pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQtr0nJSfifu"
      },
      "source": [
        "### Data cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oSo_4u1fifu"
      },
      "source": [
        "#### Remove unnecessary data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HbUiPVefifu"
      },
      "source": [
        "Now that we have covered some basics of data exporting and viewing, let's see how we can clean our sample dataset for further analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-cDdn51fifv"
      },
      "source": [
        "First of all, let's delete the \"Source\" column we just created. To do this, we will use **drop()** method. Its *axis* parameter identifies whether we want to drop labels from the index (0 or ‘index’) or columns (1 or ‘columns’):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObDLN98bfifw"
      },
      "source": [
        "#drop \"Source', 'SNo', and 'LastUpdate' columns:\n",
        "covid = covid.drop(['Source', 'Last Update', 'SNo'], axis = 1)\n",
        "covid.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeWFmMVafifx"
      },
      "source": [
        "(Here, we also dropped 'SNo' column, which is basically another index column, and 'Last Update' column since it was showing time in UTC at which the row is updated for the given province or country.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yjO_o-Jfifx"
      },
      "source": [
        "#To drop a row (or multiple rows) by index, we would use the following syntax:\n",
        "#covid.drop([0, 1]) - drop first two rows"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjeJgHBQfifx"
      },
      "source": [
        "#### Rename columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYos2P8Ififx"
      },
      "source": [
        "Sometimes, data sets we are working with come with column names or index names which are not very convenient. For example, we have 'Province/State' and 'Country/Region' columns which have special characters in their names, and also 'Last Update' column with a space in it. Let's rename them:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KWm7Fgmfify"
      },
      "source": [
        "#Rename 'Province/State' column to a 'Region', and 'Country/Region' column to a 'Country':\n",
        "covid = covid.rename(columns = {'Province/State': 'Region', 'Country/Region': 'Country'})\n",
        "covid.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTttnbHGfify"
      },
      "source": [
        "#### Remove duplicate records"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYJB6VXpfify"
      },
      "source": [
        "First, we check if there are any duplicate records using **duplicated()** method which returns boolean True/False values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA52q-JOfify"
      },
      "source": [
        "# NOT SUPPORTED IN RAPIDS\n",
        "covid.duplicated().head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPIV2jW7fify"
      },
      "source": [
        "Of course we do not want to scrool through thousands of returned True/False. Instead, we can check for unique vaules:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1AUloHbfifz"
      },
      "source": [
        "#Check for duplicated values using unique() method:\n",
        "covid.drop_duplicates().shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4C-yEWLfifz"
      },
      "source": [
        "covid.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-5PLcCNfifz"
      },
      "source": [
        "To remove duplicated records from the DataFrame, we would use the following syntax:\n",
        "\n",
        "**df = df.drop_duplicates()**\n",
        "\n",
        "To remove duplicates of only one or a subset of columns, we can specify *subset* as the individual column or list of columns that should be unique:\n",
        "\n",
        "**df.drop_duplicates(subset = ['Column_1', 'Column_2'], keep = 'False')**\n",
        "\n",
        "We can do the same task conditional on a different column’s value. In such case we can **sort_values()** first, and specify **keep** equals either first or last:\n",
        "\n",
        "**df.sort_values('Column_1', ascending=False)**\n",
        "\n",
        "**df = df.drop_duplicates(subset='Column_2', keep='first')**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id_3NcHSfifz"
      },
      "source": [
        "#### Data types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiwdyYPJfifz"
      },
      "source": [
        "We should also investigate data types within our dataframe. To do this, we use **dtype** (for a Series) or **dtypes** (for a DataFrame) attribute:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCTjVf2nfif0"
      },
      "source": [
        "#check all data types within our dataset:\n",
        "covid.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uqx0Y_Yfif0"
      },
      "source": [
        "#check data type of specific column:\n",
        "covid.Confirmed.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxirEzzDfif0"
      },
      "source": [
        "Note that columns consisting entirely of strings do not get their own type in pandas; they are instead given the object type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChbLfgXKfif0"
      },
      "source": [
        "Sometimes we would like to convert a column of one type into another wherever such a conversion makes sense by using the **astype()** function. In our dataframe, we may transform the *Deaths* column from its existing float64 data type into a int64 data type:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3Y-EEjWfif0"
      },
      "source": [
        "#Convert 'Deaths' values to integers:\n",
        "covid.Deaths = covid.Deaths.fillna(0).astype('int64')\n",
        "covid.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzwv1WiGfif1"
      },
      "source": [
        "Also, to make work with dates easier, let's convert 'ObservationDate' column to pandas *datetime* object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywMENm09fif1"
      },
      "source": [
        "#Convert ObservationDate column to datetime:\n",
        "covid['ObservationDate'] = cudf.to_datetime(covid.ObservationDate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YEl1rJNfif1"
      },
      "source": [
        "covid.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nURqzk5Wfif1"
      },
      "source": [
        "#### Convert strings to uppercase:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRGptcEffif1"
      },
      "source": [
        "Many times, when we work with string data in our data set, it might be a good idea to convert all characters to uppercase and strip extra whitespaces before and after each string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1mtufC5fif2"
      },
      "source": [
        "covid.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3EQEk1Qfif2"
      },
      "source": [
        "Let's modify strings within the 'Region' and 'Country' Series of our data set. To convert strings in the Series/Index to uppercase, we can use **upper()** method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ebbe6Ruifif2"
      },
      "source": [
        "#Convert 'Region' and 'Country' to uppercase:\n",
        "covid.Region = covid.Region.str.upper()\n",
        "covid.Country = covid.Country.str.upper()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNCSRcSPfif2"
      },
      "source": [
        "covid.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJNU8oUGfif2"
      },
      "source": [
        "To remove leading and trailing characters, we would use **strip()** method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1RfvOAMfif2"
      },
      "source": [
        "covid.Region = covid.Region.str.strip()\n",
        "covid.Country = covid.Country.str.strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXyTdMPDfif3"
      },
      "source": [
        "Note: Sometimes, we might want to remove leading (**lstrip()**) or trailing (**rstrip()**) characters only."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8itESCFmfif3"
      },
      "source": [
        "#### Missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIR31ihefif3"
      },
      "source": [
        "Usually, when we work with real-world data, we always have some missing records. To find these missing values, also known as **NaN** (Not a Number), in our data set, we would use **isnull** method (or, alternatively, **notnull()** method which will select not empty values)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9HMaJcAfif3"
      },
      "source": [
        "#Check which coumns in our data set have missing values:\n",
        "covid.isnull().any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwkMXxQWfif3"
      },
      "source": [
        "covid[covid.Region.isnull()].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txAVokp-fif3"
      },
      "source": [
        "#Check how many values are missing:\n",
        "percent_missing = covid.isnull().sum() * 100 / len(covid)\n",
        "missing_df = cudf.DataFrame({'column_name': covid.columns,\n",
        "                                 'percent_missing': percent_missing})\n",
        "missing_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhPKoGhzfif4"
      },
      "source": [
        "To perform data analysis, we would like to replace missing values, and pandas provides a really handy method for this problem: **fillna()**. \n",
        "\n",
        "In our case, we can simply replace each NaN with an 'Unknown':"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS9zRrcyfif4"
      },
      "source": [
        "#To drop all the missing values in one column:\n",
        "#df = df.dropna(subset = ['Column_Name'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0D85FE2fif4"
      },
      "source": [
        "#Replace missing 'Region' calues with 'Unknown':\n",
        "covid['Region'] = covid['Region'].fillna('Unknown')\n",
        "covid.iloc[35:40]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXFmHlSefif4"
      },
      "source": [
        "covid.isnull().any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTNfGkEzfif5"
      },
      "source": [
        "Sometimes it makes sense to remove missing values from data set, and in that case we would use **dropna()** method. By default, **dropna()** will drop all rows in which any null value is present:\n",
        "\n",
        "**df.dropna()**\n",
        "\n",
        "We can also drop missing values along a different axis; *axis=1* drops all columns containing a null value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bp5unH6fif5"
      },
      "source": [
        "### Summary statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me0y1nicfif5"
      },
      "source": [
        "Pandas provides some handy methods which allow us to see a high-level summary of data. We already familiar with one of these methods - **describe()**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xVjLstGfif5"
      },
      "source": [
        "#Applied to numerical data:\n",
        "covid.Confirmed.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWEU48pn4mM8"
      },
      "source": [
        "covid.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RKCjCsg4ait"
      },
      "source": [
        "#Applied to string data:\n",
        "# NOT SUPPORTED IN RAPIDS!!!\n",
        "covid.Country.describe()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2B7-0uDhfif5"
      },
      "source": [
        "For the reference, here are some others commonly used methods (they can be applies to a Series as well):\n",
        "\n",
        "**df.describe()** - summary statistics for numerical columns\n",
        "\n",
        "**df.mean()** - returns the mean of all columns\n",
        "\n",
        "**df.corr()** - returns the correlation between columns in a DataFrame\n",
        "\n",
        "**df.count()** - returns the number of non-null values in each DataFrame column\n",
        "\n",
        "**df.max()** - returns the highest value in each column\n",
        "\n",
        "**df.min()** - returns the lowest value in each column\n",
        "\n",
        "**df.median()** - returns the median of each column\n",
        "\n",
        "**df.std()** - returns the standard deviation of each column\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ObYgIqffif6"
      },
      "source": [
        "To see a list of all unique values in certain Series, we would use the **unique()** method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAKD14zofif6"
      },
      "source": [
        "#See the list of unique 'Country' values:\n",
        "covid.Country.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwsHO7LBfif6"
      },
      "source": [
        "**nunique()** will return a number of unique values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SNRRd9Vfif6"
      },
      "source": [
        "#Number of unique countries:\n",
        "covid.Country.nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCC4AD1bfif6"
      },
      "source": [
        "### Data transformations with 'map' and 'apply'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqEiPM2Zfif7"
      },
      "source": [
        "There are two methods in pandas which allow us to take one set of values and \"map\" them to another set. **map()** returns a new Series where all the values have been transformed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLQBSC1Nfif7"
      },
      "source": [
        "Let's say we have noticed that 'Country' Series contains, among others, entries for 'Mainland China', 'Hong Kong', and 'Macau'. We know that they are all parts of People's Republic of China, and would prefer to use 'China' for all of them. Here is how this can be done:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezpqJSnHfif7"
      },
      "source": [
        "s = set(['MAINLAND CHINA', 'HONG KONG', 'MACAU'])\n",
        "\n",
        "country_pandas = covid['Country'].to_pandas()\n",
        "\n",
        "country_pandas_fixed = country_pandas.map(lambda x: 'CHINA' if x in s else x)\n",
        "country_pandas_fixed.head()\n",
        "covid['GeneralCountry'] = country_pandas_fixed\n",
        "covid.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXsm4dIW4_S1"
      },
      "source": [
        "Let's say we needed to adjust our confirmed up by a single case for every observation. For this, we can use the `applymap` method on a single _numeric_ `cudf` column (`Series`) in the `DataFrame`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyZfKH-A49O4"
      },
      "source": [
        "covid['Confirmed_Adjusted'] = covid['Confirmed'].applymap(lambda x: x + 1.0)\n",
        "covid.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR58vH835a4p"
      },
      "source": [
        "covid.groupby('Country').agg(\n",
        "    {\n",
        "        'Deaths':'count', \n",
        "        'ObservationDate': ['min','max']\n",
        "     \n",
        "    }\n",
        ").sort_values(('ObservationDate','min'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bjN-hjSfif7"
      },
      "source": [
        "Here we used a small anonimous function (*lambda function*) which can take any number of arguments, but can only have one expression. Once the expression is executed, it returns the result.\n",
        "\n",
        "In our example, this lambda function takes a single value from the 'Country' Series, and return a transformed version of that value. Then **map()** returns a new Series (which we called 'GeneralCountry' where all the values have been transformed by our labmda function.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPEQ3fCgfif8"
      },
      "source": [
        "**apply_rows()** is a similar method which be applied to DataFrames. The difference is that **apply_rows()** works on a row/column basis of a DataFrame, while **map()** works element-wise on a Series.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syyp5Geofif8"
      },
      "source": [
        "Let's create a function which calculates \"naive\" mortality rate, and write its output in a new 'MortalityRate' column using **apply_rows()** method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmGPnt0xfif8"
      },
      "source": [
        "#Create MortalityRate column using apply() method:\n",
        "import numpy as np\n",
        "def naive_rate(deaths, confirmed, MortalityRate):\n",
        "    for it, (d, c) in enumerate(zip(deaths, confirmed)):\n",
        "        if c > 0:\n",
        "            MortalityRate[it] = d/c\n",
        "        else:\n",
        "            MortalityRate[it] = 0\n",
        "            \n",
        "covid = covid.apply_rows(naive_rate,\n",
        "                   incols={'Deaths':'deaths', 'Confirmed':'confirmed'},\n",
        "                   outcols={'MortalityRate': np.float64},\n",
        "                   kwargs={}\n",
        "                  )\n",
        "covid[covid.MortalityRate != 0].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqxrzEUNfif8"
      },
      "source": [
        "### Sorting "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCSkv3Dtfif8"
      },
      "source": [
        "In many cases, we would like to first sort values in our data set, and then perform further data manipulations. To sort data and get it in the desired order we can use **sort_values()** method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFqyJ-mhfif9"
      },
      "source": [
        "#Sort values by 'GeneralCountry':\n",
        "covid.sort_values(by = 'GeneralCountry').head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JiBmPsMfigF"
      },
      "source": [
        "**sort_values()** defaults to an ascending sort, where the lowest values go first. To obtain a descending sort, we need to specify *ascending* parameter: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwUAgo56figF"
      },
      "source": [
        "#Sort values by 'ObservationDate' and 'Confirmed' in descending order:\n",
        "covid.sort_values(by = ['ObservationDate', 'Confirmed'], ascending = False).head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYnlm9uifigG"
      },
      "source": [
        "### Grouping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZWV48CrfigG"
      },
      "source": [
        "Depending on our goals, we might prefer to group data first, and then perform some operations on this group. In pandas, we can do it with **groupby()** method. However, simple call of a *groupby* method on our data set will return not a set of DataFrames, but a DataFrameGroupBy object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkXj7kaMfigG"
      },
      "source": [
        "#Group by 'GeneralCountry' and create a DataFrameGroupBy object:\n",
        "covid.groupby('GeneralCountry')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUEkMpm9figG"
      },
      "source": [
        "We can think of this object as of a special view of the DataFrame, which is already divided into groups. To get actual results, we need to apply an aggregate on this object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KF5_rebfigG"
      },
      "source": [
        "#For example, we can check when the date of latest observation for each country:\n",
        "covid.groupby('GeneralCountry').ObservationDate.max().head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-cziF5YfigH"
      },
      "source": [
        "#Let's fix this ('ST. MARTIN') business:\n",
        "covid['GeneralCountry'] = covid.GeneralCountry.str.strip(\"('\")\n",
        "covid.groupby('GeneralCountry').ObservationDate.max().head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMuu19V4figH"
      },
      "source": [
        "Similarly, we can use any of the summary functions with groupby object. For example, we can see latest numbers of confirmed cases within various regions of China:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O22c7h0figH"
      },
      "source": [
        "covid[covid.GeneralCountry == 'CHINA'].groupby('Region').Confirmed.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvjFz6HPfigH"
      },
      "source": [
        "We can also group by more than one column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eBfxgTxfigI"
      },
      "source": [
        "#Group by 'GeneralCountry' and 'Region' and see maximum (=total) number of 'Deaths':\n",
        "covid.groupby(['GeneralCountry', 'Region']).Deaths.max().head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1BdGdx8figI"
      },
      "source": [
        "#Number of regions within each country:\n",
        "covid.groupby('GeneralCountry').Region.nunique().head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm2i-FfrfigI"
      },
      "source": [
        "#See 'Confirmed' and 'Deaths' numbers by GeneralCountry:\n",
        "covid.groupby('GeneralCountry')[['Confirmed', 'Deaths']].max().head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mm2MlcVfigI"
      },
      "source": [
        "**reset_index()** method allows to reset index:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdhT1TNXfigI"
      },
      "source": [
        "#Reset index in just created dataframe:\n",
        "covid.groupby('GeneralCountry')[['Confirmed', 'Deaths']].max().reset_index().head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRzg_kqh8K9U"
      },
      "source": [
        "We can also use the `agg()` method to perform more general aggregations subsets of columns of our dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvsHAzie8KHa"
      },
      "source": [
        "covid.groupby('Country').agg(\n",
        "    {\n",
        "        'Deaths':'count', \n",
        "        'ObservationDate': ['min','max']\n",
        "     \n",
        "    }\n",
        ").sort_values(('ObservationDate','min'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCK2LKsMfigJ"
      },
      "source": [
        "### Joining data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17squVTjfigJ"
      },
      "source": [
        "Often enough, while analyzing data, we need to combine different DataFrames and/or Series in non-trivial ways. Pandas has a few neat methods for doing this. \n",
        "\n",
        "In cases when we have data in different DataFrames (or Series) but having the same fields (columns), **concat()** function lets us join dataframes along axis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtAeZFcOfigJ"
      },
      "source": [
        "Let's say we create a new DataFrame using *groupby()* method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK0FYGJAfigK"
      },
      "source": [
        "countries_stats = covid.groupby('GeneralCountry')[['Confirmed', 'Deaths']].max().reset_index()\n",
        "countries_stats.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxXrLeKFfigK"
      },
      "source": [
        "And pretend we have just heard of two new confirmed cases - one in Mongolia, and one in Jamaica:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZvtY9X5figK"
      },
      "source": [
        "new_cases = pd.DataFrame({'GeneralCountry': ['MONGOLIA', 'JAMAICA'], 'Confirmed': [1.0, 1.0], 'Deaths': [0, 0]})\n",
        "new_cases"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQF3L0kUfigK"
      },
      "source": [
        "Now if we would like to study all of the affected countries simultaneously, we would use **concat()** method to stack these two DataFrames on top of one another:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBF6zCTifigK"
      },
      "source": [
        "#Concatenate counties_stats and new_cases in new 'all_cases' DataFrame:\n",
        "all_cases = pd.concat([countries_stats, new_cases])\n",
        "all_cases.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vRlRg4ofigL"
      },
      "source": [
        "#Check:\n",
        "all_cases[all_cases.GeneralCountry == 'JAMAICA']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6UU5X8bfigL"
      },
      "source": [
        "To concat the same two DataFrames along columns, we would switch *axis* parameter to 1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWPpAH7cfigL"
      },
      "source": [
        "#Concatenate the same DataFrames along  columns:\n",
        "all_cases_too = pd.concat([countries_stats, new_cases], axis = 1)\n",
        "all_cases_too.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mjweoCCfigL"
      },
      "source": [
        "**merge()** or **join()** methods let you combine different DataFrame objects which have an index in common (similar to a JOIN in SQL). Th **join** method works the best when we need to join dataframes on their indexes, while the **merge** is more versatile.\n",
        "\n",
        "Let's create a new DataFrame listing countries and latest observation dates:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYEP7EoSfigM"
      },
      "source": [
        "#Create a new DataFrame with countries and latest observation dates:\n",
        "latest_data = covid.groupby(['GeneralCountry', 'Region']).ObservationDate.max().reset_index()\n",
        "latest_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh9dgcOJfigM"
      },
      "source": [
        "Now we want to join this DataFrame with our original 'covid' DataFrame to get latest fatality rates:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rlptnmi_figM"
      },
      "source": [
        "latest_rates = pd.merge(latest_data, covid[['GeneralCountry', 'Region', 'ObservationDate', 'MortalityRate']], \\\n",
        "                        on=['GeneralCountry', 'Region', 'ObservationDate'])\n",
        "latest_rates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHd0aTR3figM"
      },
      "source": [
        "We can also specify if we need inner, outer, right, or left join, as well as add a suffix to duplicate column names:\n",
        "\n",
        "**pd.merge(df_1, df_2, on='ID', how='left', suffixes=('_1', '_2'))**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMMegiavfigM"
      },
      "source": [
        "### Pivot tables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcBExiCvfigN"
      },
      "source": [
        "With pandas, we can also create a spreadsheet-style pivot table as a DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1VCwziWfigN"
      },
      "source": [
        "#Create an Excel-style pivot table:\n",
        "pd.pivot_table(covid[['GeneralCountry', 'Region', 'ObservationDate', 'Confirmed']], \\\n",
        "               index=['GeneralCountry','Region'], aggfunc='max')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaT68NpdfigN"
      },
      "source": [
        "### Data visualizations with pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ke12AdG6figN"
      },
      "source": [
        "When we want to quickly view how our data looks, pandas visualizations come in handy.\n",
        "\n",
        "Let's look again at *all_cases* DataFrame we created some time ago:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDsfNlIJfigN"
      },
      "source": [
        "#Look at first 5 rows of 'all_cases' DataFrame:\n",
        "all_cases.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DopQ7tyUfigN"
      },
      "source": [
        "Pandas visualizations are built on top of famous **matplotlib** library.\n",
        "The standard convention for referencing the matplotlib API:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7l781KprfigO"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21FxQ6oxfigP"
      },
      "source": [
        "To make sure all plots are visible within our notebook, use this magic command:\n",
        "\n",
        "**%matplotlib inline**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cX5ryQu1figP"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "395XXwYxfigP"
      },
      "source": [
        "To build charts with pandas, we use basic **plot()** method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIF94sH_figP"
      },
      "source": [
        "#Let's look at all confirmed cases by date:\n",
        "by_date = covid.groupby('ObservationDate').Confirmed.sum().reset_index()\n",
        "by_date.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "520_axGAfigT"
      },
      "source": [
        "#Now let's visualize this with simple line chart:\n",
        "by_date.plot.line(x = 'ObservationDate', y = 'Confirmed', color = 'purple', title = 'COVID-19 confirmed cases: World')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbLj_B2PfigT"
      },
      "source": [
        "Let us now build a similar plot for US only:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cn06WmZfigT"
      },
      "source": [
        "#Create a new 'us_daily' DataFrame with US-only data:\n",
        "us_daily = covid[covid.GeneralCountry == 'US'].groupby('ObservationDate').sum().reset_index()\n",
        "us_daily"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUtQ8xiEfigT"
      },
      "source": [
        "#create a line chart:\n",
        "us_daily.plot.line(x = 'ObservationDate', y = 'Confirmed', color = 'brown', title = 'COVID-19 confirmed cases: US')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFcf6QIMfigU"
      },
      "source": [
        "Let's look at total number of cases and deaths by country:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY61nNm1figU"
      },
      "source": [
        "#First, let's group everything by GeneralCountry & Region and get latest numbers of confirmed cases and deaths:\n",
        "world_regions = covid.groupby(['GeneralCountry', 'Region'])[['Confirmed', 'Deaths']].max().reset_index()\n",
        "world_regions.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7-6T_W2figU"
      },
      "source": [
        "#Then we can get total latest numbers for each country:\n",
        "world = world_regions.groupby('GeneralCountry')[['Confirmed', 'Deaths']].sum().reset_index()\n",
        "world.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yI1H9qjfigU"
      },
      "source": [
        "#One of the basic and widely used plots - bar chart:\n",
        "world.plot(kind = 'bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lPkU8ubfigV"
      },
      "source": [
        "Let's try to make it looking a bit more appealing by visualizing top 10 countries only, and make horizontal bar chart, instead:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKGDLlsAfigV"
      },
      "source": [
        "#Create a DataFrame with top 10 COVID-19 confirmed cases:\n",
        "top = world.sort_values(by = 'Confirmed', ascending = False).head(10)\n",
        "top"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGUQygkhfigV"
      },
      "source": [
        "A little trick to make your dataframe look more presentable by adding background color (using matplotlib built-in colormaps (**cmap**)):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1ZUUrLbfigV"
      },
      "source": [
        "top10 = top.style.background_gradient(cmap='Blues',subset=[\"Confirmed\"]).background_gradient(cmap='Reds',subset=[\"Deaths\"])\n",
        "top10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGRTY0dxfigW"
      },
      "source": [
        "Now let's plot the simplest bar chart:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGDHlQ8VfigX"
      },
      "source": [
        "#Plot the bar chart with 'top' data:\n",
        "top.plot.bar()\n",
        "\n",
        "#another way of getting the same result is:\n",
        "#top.plot(kind = 'bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNEh7aOyfigX"
      },
      "source": [
        "Here, by default, **plot()** method built index values on x-axis. Let's specify that we want to see countries names, instead:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26v_e342figX"
      },
      "source": [
        "top.plot.bar(x = 'GeneralCountry')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LSthu18figX"
      },
      "source": [
        "#Convert this to horizontal bar chart:\n",
        "top.index = top.GeneralCountry\n",
        "top.plot.barh()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m86qIN_WfigX"
      },
      "source": [
        "#Modify some more:\n",
        "top.index = top.GeneralCountry\n",
        "top.plot.barh(title = 'Top 10 Countries (Confirmed Cases and Deaths)', figsize = [10,7],\\\n",
        "             fontsize = 12, color = ['blue', 'red']).invert_yaxis()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZdCVIiXfigY"
      },
      "source": [
        "### Plotting with Plotly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvJ5OV8hfigY"
      },
      "source": [
        "The plotly Python library is an interactive, open-source plotting library that supports over 40 unique chart types covering a wide range of statistical, financial, geographic, scientific, and 3-dimensional use-cases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WKv8CYGfigZ"
      },
      "source": [
        "#Import plotly and check its version:\n",
        "import plotly\n",
        "plotly.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdoZ4R-QfigZ"
      },
      "source": [
        "In case you do not have plotly installed, run the following line in your Anaconda prompt:\n",
        "\n",
        "**conda install -c plotly plotly=4.6.0**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF87qeKofigZ"
      },
      "source": [
        "We are going to use Plotly Express, which is easy-to-use, high-level interface to Plotly, which produces easy-to-style figures. Every Plotly Express function returns a graph_objects.Figure object whose data and layout has been pre-populated according to the provided arguments.\n",
        "\n",
        "Note: Plotly Express was previously its own separately-installed **plotly_express** package but is now part of plotly and importable via \n",
        "\n",
        "**import plotly.express as px**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANrEmbU0figZ"
      },
      "source": [
        "import plotly.express as px\n",
        "import numpy as np\n",
        "temp_df = pd.DataFrame(world)\n",
        "temp_df = temp_df.reset_index()\n",
        "fig = px.choropleth(temp_df, locations=\"GeneralCountry\",\n",
        "                    color=np.log10(temp_df[\"Confirmed\"]), \n",
        "                    hover_name=\"index\", # column to add to hover information\n",
        "                    hover_data=[\"Confirmed\"],\n",
        "                    color_continuous_scale=px.colors.sequential.Plasma,locationmode=\"country names\")\n",
        "fig.update_geos(fitbounds=\"locations\", visible=False)\n",
        "fig.update_layout(title_text=\"Confirmed Cases Heat Map (Log Scale)\")\n",
        "fig.update_coloraxes(colorbar_title=\"Confirmed Cases(Log Scale)\",colorscale=\"Blues\")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx5Zkcpzfigh"
      },
      "source": [
        "#Another example visualizing progression of COVID-19 spread across the continents:\n",
        "df_data = covid.groupby(['ObservationDate', 'GeneralCountry'])['Confirmed', 'Deaths'].max().reset_index().fillna(0)\n",
        "df_data[\"ObservationDate\"] = pd.to_datetime( df_data[\"ObservationDate\"]).dt.strftime('%m/%d/%Y')\n",
        "fig = px.scatter_geo(df_data, locations=\"GeneralCountry\", locationmode='country names', \n",
        "                     color=np.power(df_data[\"Confirmed\"],0.3)-2 , size= np.power(df_data[\"Confirmed\"]+1,0.3)-1, hover_name=\"GeneralCountry\",\n",
        "                     hover_data=[\"Confirmed\"],\n",
        "                     range_color= [0, max(np.power(world[\"Confirmed\"],0.3))], \n",
        "                     projection=\"natural earth\", animation_frame=\"ObservationDate\", \n",
        "                     color_continuous_scale=px.colors.sequential.Plasma,\n",
        "                     title='COVID-19: Progression of spread'\n",
        "                    )\n",
        "fig.update_coloraxes(colorscale=\"hot\")\n",
        "fig.update(layout_coloraxis_showscale=False)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0DeVuS0figs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}